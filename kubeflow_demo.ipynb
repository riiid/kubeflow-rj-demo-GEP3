{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f863845e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90fc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import dill\n",
    "import torch\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c28dc5",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df8e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs        = 150\n",
    "batch_size    = 32\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e0b0b",
   "metadata": {},
   "source": [
    "# Read data and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348e828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data = pd.read_csv('StudentsPerformance.csv')\n",
    "feature_X = data.iloc[:, :5]\n",
    "target = data['math score']\n",
    "target = target/target.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c6ca2",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3655b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_encoded, target, test_size=0.10, random_state=1)\n",
    "\n",
    "# Separate 10% of training data as validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(feature_X)\n",
    "feature_encoded = ohe.transform(feature_X)\n",
    "feature_encoded = pd.DataFrame(feature_encoded.toarray())\n",
    "feature_size  = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e977c",
   "metadata": {},
   "source": [
    "# Training test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7b308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23962562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputData(Dataset):\n",
    "    \n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target   = target\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.target[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.features)\n",
    "\n",
    "train_dataset = InputData(torch.from_numpy(X_train.values).float(), torch.from_numpy(y_train.values).float())\n",
    "val_dataset   = InputData(torch.from_numpy(X_val.values).float(),   torch.from_numpy(y_val.values).float())\n",
    "test_dataset  = InputData(torch.from_numpy(X_test.values).float(),  torch.from_numpy(y_test.values).float())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f673b4",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829c91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset  = train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(dataset  = val_dataset,   batch_size=1)\n",
    "test_loader  = DataLoader(dataset  = test_dataset,  batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca458ce0",
   "metadata": {},
   "source": [
    "# Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1eda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Regression, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 16)\n",
    "        self.layer_2 = nn.Linear(16, 10)\n",
    "        self.out = nn.Linear(10, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.out(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eed9768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started !!!\n",
      "0.22132039070129395 0.20992720127105713\n",
      "0.13580422103405 0.11451031267642975\n",
      "0.05662846937775612 0.09548471868038177\n",
      "0.002188674174249172 0.021542105823755264\n",
      "0.002020004903897643 0.027117732912302017\n",
      "0.0006218467024154961 0.016726108267903328\n",
      "0.00030033683287911117 0.018831761553883553\n",
      "0.00017998565454035997 0.02517317607998848\n",
      "7.913763693068177e-05 0.023975053802132607\n",
      "3.638206180767156e-06 0.014302466996014118\n",
      "6.681041122647002e-05 0.0224201250821352\n",
      "1.0151276001124643e-05 0.008712304756045341\n",
      "2.9789734981022775e-05 0.02287457324564457\n",
      "8.351372002834978e-07 0.008252376690506935\n",
      "6.57448181300424e-05 0.018535520881414413\n",
      "3.0695049645146355e-05 0.03268510848283768\n",
      "1.667119431658648e-05 0.034128863364458084\n",
      "1.0424658285046462e-05 0.024841878563165665\n",
      "3.14385488309199e-07 0.014801422134041786\n",
      "0.00011366848775651306 0.016000036150217056\n",
      "3.293308327556588e-05 0.023629222065210342\n",
      "1.2333900485828053e-05 0.014173755422234535\n",
      "3.248806024203077e-08 0.02146102488040924\n",
      "6.21090002823621e-05 0.014683723449707031\n",
      "1.8103983165929094e-05 0.016179578378796577\n",
      "7.933712913654745e-05 0.02001682110130787\n",
      "1.5466712284251116e-05 0.0195789597928524\n",
      "2.676268013601657e-05 0.01645522005856037\n",
      "4.393798008095473e-05 0.028904955834150314\n",
      "6.798873073421419e-05 0.02641170658171177\n",
      "7.069162393236184e-07 0.014435483142733574\n",
      "3.670270598377101e-05 0.006665420718491077\n",
      "9.988897363655269e-05 0.008157974109053612\n",
      "1.600047312422248e-06 0.018512487411499023\n",
      "1.9408373646001564e-06 0.0188380628824234\n",
      "3.244915569666773e-05 0.01563437469303608\n",
      "2.6165384042542428e-05 0.017255747690796852\n",
      "9.00139712030068e-05 0.015170460566878319\n",
      "3.452743112575263e-05 0.016603322699666023\n",
      "4.19955285906326e-05 0.019088277593255043\n",
      "3.190346251358278e-05 0.011704173870384693\n",
      "3.972796548623592e-05 0.025593426078557968\n",
      "5.748143667005934e-05 0.017771365121006966\n",
      "9.503728506388143e-06 0.02374928817152977\n",
      "0.00031987426336854696 0.01824013702571392\n",
      "1.1498258345454815e-07 0.01080162450671196\n",
      "0.0001456072204746306 0.015232888981699944\n",
      "0.0001331233506789431 0.01336053479462862\n",
      "1.899470589705743e-05 0.024356316775083542\n",
      "7.922249642433599e-05 0.012685732915997505\n",
      "1.946149677678477e-05 0.019747432321310043\n",
      "1.0547043984843185e-06 0.0062920465134084225\n",
      "0.00016997336933854967 0.01585010439157486\n",
      "0.00010403926717117429 0.01653897389769554\n",
      "4.804546551895328e-05 0.01687650941312313\n",
      "6.552784270752454e-06 0.025152260437607765\n",
      "0.0001689398632152006 0.015407102182507515\n",
      "6.515075074275956e-05 0.02765513025224209\n",
      "3.5184687021683203e-06 0.016073953360319138\n",
      "7.019776603556238e-06 0.01814430020749569\n",
      "6.377891281772463e-08 0.01182144321501255\n",
      "0.00020549839246086776 0.011591015383601189\n",
      "4.4513526518130675e-05 0.007671118713915348\n",
      "4.3016760173486546e-05 0.017594266682863235\n",
      "9.53522976487875e-05 0.00889485515654087\n",
      "5.107193828735035e-06 0.010571986436843872\n",
      "3.3684365916997194e-05 0.012841683812439442\n",
      "0.0002531309437472373 0.006737393327057362\n",
      "3.764464781852439e-05 0.012454403564333916\n",
      "0.0003306971048004925 0.021865930408239365\n",
      "9.28074077819474e-05 0.023699238896369934\n",
      "1.0317549481442256e-07 0.01133678387850523\n",
      "0.00016403329209424555 0.008557412773370743\n",
      "2.5530341645207955e-06 0.01279032789170742\n",
      "0.0001330298400716856 0.02133956551551819\n",
      "2.488980499038007e-05 0.0077397143468260765\n",
      "0.0002889824390877038 0.016938386484980583\n",
      "2.6650557629182003e-05 0.011352992616593838\n",
      "7.838754072508891e-07 0.024406250566244125\n",
      "8.974951197160408e-05 0.015065697953104973\n",
      "9.612212306819856e-05 0.005351451225578785\n",
      "4.703324975707801e-06 0.012391554191708565\n",
      "0.00017506985750515014 0.015310285612940788\n",
      "0.00010795423440868035 0.01508998591452837\n",
      "0.00027452645008452237 0.028942828997969627\n",
      "0.00029987425659783185 0.028463494032621384\n",
      "0.00033557959250174463 0.018597526475787163\n",
      "0.0004012041608802974 0.031224612146615982\n",
      "0.0005825611879117787 0.020838338881731033\n",
      "0.0002419458032818511 0.024584610015153885\n",
      "0.00024481723085045815 0.018661024048924446\n",
      "0.00043117065797559917 0.013847860507667065\n",
      "0.0002058505779132247 0.008472343906760216\n",
      "0.00044352569966576993 0.012390145100653172\n",
      "0.00043809949420392513 0.020368898287415504\n",
      "8.353224257007241e-05 0.005232873372733593\n",
      "0.0003856066323351115 0.016248691827058792\n",
      "0.0005573502858169377 0.02801128663122654\n",
      "0.00011676758003886789 0.015394936315715313\n",
      "0.001207863911986351 0.027614641934633255\n",
      "0.0003405726747587323 0.02083534374833107\n",
      "0.0006545248907059431 0.016894156113266945\n",
      "0.0005394398467615247 0.01933627389371395\n",
      "0.00024154543643817306 0.011509394273161888\n",
      "0.0003918137226719409 0.022566772997379303\n",
      "0.0008306564413942397 0.011708310805261135\n",
      "0.0008619253640063107 0.021519720554351807\n",
      "0.0001119011576520279 0.010140311904251575\n",
      "0.0005411799647845328 0.012052771635353565\n",
      "6.626974936807528e-05 0.011455526575446129\n",
      "0.00029397683101706207 0.0174186360090971\n",
      "0.00022671766055282205 0.020639080554246902\n",
      "0.00011353888839948922 0.030533498153090477\n",
      "3.356201705173589e-05 0.01570279523730278\n",
      "0.0012207330437377095 0.011438386514782906\n",
      "0.00014077586820349097 0.031075065955519676\n",
      "0.0003119795292150229 0.0037684799171984196\n",
      "0.00025585037656128407 0.022663870826363564\n",
      "0.00023494362540077418 0.01516895554959774\n",
      "4.442608405952342e-05 0.020242972299456596\n",
      "2.066021124846884e-06 0.02303825132548809\n",
      "0.00021210250270087272 0.009094445034861565\n",
      "0.0002050031180260703 0.01764827035367489\n",
      "0.0001811373804230243 0.005249470937997103\n",
      "0.0005775282625108957 0.014661392197012901\n",
      "0.0001908670092234388 0.01572628691792488\n",
      "7.367623038589954e-05 0.006424269173294306\n",
      "0.00013565088738687336 0.022944841533899307\n",
      "0.0005396502674557269 0.014164524152874947\n",
      "4.994115442968905e-05 0.021728655323386192\n",
      "0.00015258784696925431 0.017862267792224884\n",
      "0.00017720887262839824 0.008097800426185131\n",
      "1.0094005119754001e-05 0.01048001367598772\n",
      "8.971676288638264e-05 0.017660116776823997\n",
      "8.289805919048376e-06 0.026494596153497696\n",
      "0.000734702218323946 0.017849009484052658\n",
      "7.170251774368808e-05 0.013155803084373474\n",
      "1.5577552403556183e-05 0.010431258007884026\n",
      "3.385270247235894e-05 0.00679846853017807\n",
      "8.7663451267872e-05 0.026980271562933922\n",
      "3.890797870553797e-07 0.013065135106444359\n",
      "1.6684825823176652e-05 0.011384865269064903\n",
      "0.0005078381509520113 0.031992148607969284\n",
      "4.631130650523119e-05 0.005933078471571207\n",
      "5.545343447010964e-05 0.021829241886734962\n",
      "0.00011896252544829622 0.011085058562457561\n",
      "2.7753888076631483e-08 0.013505389913916588\n",
      "0.00024910346837714314 0.02381673827767372\n",
      "0.00024554147967137396 0.006222395692020655\n",
      "2.8221415050211363e-05 0.011446837335824966\n",
      "6.287296400842024e-06 0.01299961842596531\n",
      "7.383286720141768e-05 0.010477915406227112\n",
      "1.6746724213589914e-05 0.023084275424480438\n",
      "1.934597094077617e-05 0.012337395921349525\n",
      "4.714966053143144e-06 0.008646415546536446\n",
      "4.813640407519415e-05 0.013696931302547455\n",
      "0.0003697725769598037 0.014398396015167236\n",
      "0.00017386843683198094 0.023397473618388176\n",
      "0.0002898808743339032 0.012051998637616634\n",
      "4.625048313755542e-05 0.018399447202682495\n",
      "0.00025393193936906755 0.007670768536627293\n",
      "0.00021228656987659633 0.009120648726820946\n",
      "0.00010260458657285199 0.01166107039898634\n",
      "0.00018375068611931056 0.017042962834239006\n",
      "0.00019970732682850212 0.01454620249569416\n",
      "0.00010451402340549976 0.017775405198335648\n",
      "8.99302976904437e-05 0.01926366239786148\n",
      "6.472902214227361e-07 0.016770225018262863\n",
      "5.740102642448619e-05 0.02305087260901928\n",
      "5.060961484559812e-06 0.013543104752898216\n",
      "0.0004039284249302 0.009419632144272327\n",
      "8.268782494269544e-07 0.02726302109658718\n",
      "9.280166705138981e-05 0.02156788855791092\n",
      "0.00010313779057469219 0.011423616670072079\n",
      "4.445832473720657e-06 0.017738789319992065\n",
      "0.0006496482528746128 0.01638343371450901\n",
      "1.931085716933012e-05 0.030905932188034058\n",
      "0.00015592800627928227 0.018229583278298378\n",
      "0.0003470690571703017 0.005676917731761932\n",
      "3.9024809666443616e-05 0.019682181999087334\n",
      "0.00014873962209094316 0.01892857626080513\n",
      "2.916646008088719e-05 0.02448020875453949\n",
      "0.00010949555871775374 0.024595119059085846\n",
      "1.4890977126924554e-06 0.0035511578898876905\n",
      "0.0006038454012013972 0.03309652954339981\n",
      "3.56245473085437e-05 0.014302566647529602\n",
      "0.00034778896952047944 0.008391440846025944\n",
      "2.2834103219793178e-05 0.014973183162510395\n",
      "1.653470280871261e-05 0.01635291613638401\n",
      "3.224101601517759e-05 0.018866680562496185\n",
      "8.242508556577377e-06 0.0207669697701931\n",
      "1.500790585851064e-05 0.012617254629731178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00014190824003890157 0.01434040255844593\n",
      "0.00019917702593374997 0.008114405907690525\n",
      "6.3567073084414e-05 0.0136495903134346\n",
      "2.7259616786068364e-10 0.015805793926119804\n",
      "0.000274058518698439 0.011205870658159256\n",
      "0.00019525298557709903 0.01121935062110424\n",
      "0.00014875705528538674 0.005742698907852173\n",
      "9.260539854949457e-07 0.014895841479301453\n",
      "Model input: torch.Size([1, 17])\n",
      "Model output: torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "model = Regression(feature_size)\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []}\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "print(\"Training started !!!\")\n",
    "for epoch in range(1, epochs+1):\n",
    "  \n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred = model(X_train_batch)\n",
    "      \n",
    "        train_loss = criterion(y_train_pred, y_train_batch.unsqueeze(1))\n",
    "      \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # validation    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "         model.eval()\n",
    "         for X_val_batch, y_val_batch in val_loader:\n",
    "             X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "             y_val_pred = model(X_val_batch)\n",
    "                        \n",
    "             val_loss = criterion(y_val_pred, y_val_batch.unsqueeze(1))\n",
    "\n",
    "    valIdation_loss = float(val_loss.detach().numpy())\n",
    "    training_loss   = float(train_loss.detach().numpy())\n",
    "    print(valIdation_loss, training_loss)\n",
    "\n",
    "\n",
    "X, y = next(iter(test_loader))\n",
    "print(f\"Model input: {X.size()}\")\n",
    "torch_out = model(X.to(\"cpu\"))\n",
    "print(f\"Model output: {torch_out.detach().cpu().size()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9301a",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac4fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Starts here !!!\n",
      "11.141806919574737\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Evaluation Starts here !!!\")\n",
    "\n",
    "y_pred_list = []\n",
    "with torch.no_grad():\n",
    "     model.eval()\n",
    "     for X_batch, _ in test_loader:\n",
    "         X_batch = X_batch.to(device)\n",
    "         y_test_pred = model(X_batch)\n",
    "         y_pred_list.append(y_test_pred.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "\n",
    "# Calculate MAE between predicted and target values in test set\n",
    "\n",
    "mae_DNN = mean_absolute_error(y_pred_list, y_test)*100\n",
    "print(mae_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5335a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
